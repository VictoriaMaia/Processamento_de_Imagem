{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils,plot_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_setup(n_classes, n_kernels = 32, kernel_size = (3,3)):\n",
    "  #Instancia a rede\n",
    "  cnn = Sequential()\n",
    "\n",
    "  #Camada de convolução\n",
    "  cnn.add(Conv2D(n_kernels, kernel_size,input_shape=(28, 28, 1), activation = 'relu'))\n",
    "\n",
    "  #Normaliza os feature maps\n",
    "  cnn.add(BatchNormalization())\n",
    "\n",
    "  #camada de pooling\n",
    "  cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "  #Novas camadas (opcional) de convolução e pooling\n",
    "  cnn.add(Conv2D(n_kernels, kernel_size, activation = 'relu'))\n",
    "  cnn.add(BatchNormalization())\n",
    "  cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "  #Camada de flattening\n",
    "  cnn.add(Flatten())\n",
    "\n",
    "  #Rede densa\n",
    "  n_neuronios = 128\n",
    "  # percentual de neuronios que não vou atualizar os pesos\n",
    "  taxa_dropout = 0.2\n",
    "\n",
    "  #Primeira camada oculta\n",
    "  cnn.add(Dense(units = n_neuronios, activation = 'relu'))\n",
    "  # é para ignorar\n",
    "  cnn.add(Dropout(taxa_dropout))\n",
    "\n",
    "  #Segunda camada oculta\n",
    "  cnn.add(Dense(units = n_neuronios, activation = 'relu'))\n",
    "  cnn.add(Dropout(taxa_dropout))\n",
    "\n",
    "  #Camada de saida\n",
    "  cnn.add(Dense(units = n_classes, activation = 'softmax'))\n",
    "  return cnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_data(inputs,classes):\n",
    "  N = 6\n",
    "  for i in range(N):\n",
    "    plt.subplot(N,N,i+1),plt.imshow(inputs[i],cmap = 'gray')\n",
    "    plt.title(classes[i]), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_training, y_training), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sample_data(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_training = X_training.reshape(X_training.shape[0], 28, 28, 1)\n",
    "db_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_training = db_training.astype('float32')\n",
    "db_test = db_test.astype('float32')\n",
    "db_training /= 255\n",
    "db_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_training = np_utils.to_categorical(y_training, N_CLASSES)\n",
    "classe_test = np_utils.to_categorical(y_test, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cnn_setup(N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(db_training, classe_training, batch_size = 128, epochs = 3, validation_data = (db_test, classe_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Teste da rede:\")\n",
    "resultado = classifier.evaluate(db_test, classe_test)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusão:\")\n",
    "predictions = classifier.predict(db_test)\n",
    "classes = [np.argmax(t) for t in classe_test]\n",
    "previsoes = [np.argmax(t) for t in predictions]\n",
    "conf_matrix = confusion_matrix(previsoes, classes)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
